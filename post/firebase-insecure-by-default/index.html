<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=generator content="Hugo 0.110.0"><link rel=apple-touch-icon sizes=180x180 href=https://cdn.jsdelivr.net/gh/saligrama/blog@master/static/ico/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://cdn.jsdelivr.net/gh/saligrama/blog@master/static/ico/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://cdn.jsdelivr.net/gh/saligrama/blog@master/static/ico/favicon-16x16.png><link rel=manifest href=https://cdn.jsdelivr.net/gh/saligrama/blog@master/static/ico/site.webmanifest><title>Firebase: Insecure by Default (feat. that one time our classmates tried to sue us) - Aditya's Blog</title><meta name=author content="Aditya Saligrama"><meta name=description content="Systems and security enthusiast | Stanford '24"><meta property="og:title" content="Firebase: Insecure by Default (feat. that one time our classmates tried to sue us)"><meta name=twitter:title content="Firebase: Insecure by Default (feat. that one time our classmates tried to sue us)"><meta property="og:type" content="article"><meta property="og:url" content="https://saligrama.io/blog/post/firebase-insecure-by-default/"><meta property="og:description" content="By shifting the data authorization and access restriction burden from robust programmatic systems running on a server to static security rules, backend-as-a-service platforms like Google Firebase put new app developers and their products at risk of catastrophic data breaches if utmost care is not paid to the efficacy of these rules.
This blog post details how to find such vulnerabilities in apps using Firebase as a backend. I also tell the story of one such vulnerability I found (along with Miles McCain and Cooper de Nicola) in Fizz, a popular anonymous posting platform at Stanford and other universities. Fizz&rsquo;s improper handling of Firebase security rules allowed full deanonymization of all posts down to email and/or phone number and unauthorized granting of moderator permissions.
Lastly, I talk about legal threats we received in the course of disclosing these vulnerabilities."><meta name=twitter:description content="By shifting the data authorization and access restriction burden from robust programmatic systems running on a server to static security rules, backend-as-a-service platforms like Google Firebase put new app developers and their products at risk of catastrophic data breaches if utmost care is not paid to the efficacy of these rules.
This blog post details how to find such vulnerabilities in apps using Firebase as a backend. I also tell the story of one such vulnerability I found (along with Miles McCain and Cooper de Nicola) in Fizz, a popular anonymous posting platform at Stanford and other universities. Fizz&rsquo;s improper handling of Firebase security rules allowed full deanonymization of all posts down to email and/or phone number and unauthorized granting of moderator permissions.
Lastly, I talk about legal threats we received in the course of disclosing these vulnerabilities."><meta property="og:image" content="https://opengraph-generators.vercel.app/api/blog?title=Firebase: Insecure by Default (feat. that one time our classmates tried to sue us)&date=November 14, 2022&words=3147"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://opengraph-generators.vercel.app/api/blog?title=Firebase: Insecure by Default (feat. that one time our classmates tried to sue us)&date=November 14, 2022&words=3147"><meta name=twitter:image:src content="https://opengraph-generators.vercel.app/api/blog?title=Firebase: Insecure by Default (feat. that one time our classmates tried to sue us)&date=November 14, 2022&words=3147"><meta property="article:published_time" content="2022-11-14T12:55:00-08:00"><meta property="article:modified_time" content="2022-11-14T12:55:00-08:00"><link rel=stylesheet href=https://saligrama.io/blog/assets/css/fuji.min.css><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GJHJW3T457")</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-GJHJW3T457"></script></head><body data-theme=auto data-theme-auto=true><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://saligrama.io/blog>Aditya's Blog</a>
<span class=title-sub>Thoughts, guides and fun from a security/systems enthusiast @ Stanford</span></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://saligrama.io/blog/post/firebase-insecure-by-default/>Firebase: Insecure by Default (feat. that one time our classmates tried to sue us)</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;November 14, 2022</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;3147 words</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;No tag</span></div><div class="post-content markdown-body"><p>By shifting the data authorization and access restriction burden from robust programmatic systems running on a server to static security rules, backend-as-a-service platforms like <a href=https://firebase.google.com target=_blank>Google Firebase</a> put new app developers and their products at risk of catastrophic data breaches if utmost care is not paid to the efficacy of these rules.</p><p>This blog post details how to find such vulnerabilities in apps using Firebase as a backend. I also tell the story of one such vulnerability I found (along with <a href=https://miles.land target=_blank>Miles McCain</a> and <a href=https://github.com/cdenicola target=_blank>Cooper de Nicola</a>) in <a href=https://fizzsocial.app target=_blank>Fizz</a>, a popular anonymous posting platform at Stanford and other universities. Fizz&rsquo;s improper handling of Firebase security rules allowed full deanonymization of all posts down to email and/or phone number and unauthorized granting of moderator permissions.</p><p>Lastly, I talk about legal threats we received in the course of disclosing these vulnerabilities.</p><h1 id=intro>Intro</h1><p>With software and programming starting to become almost a lingua franca of today’s world, the state of tooling for app development has become better and better in recent years in terms of usability for new developers. One such tool is <a href=https://firebase.google.com/ target=_blank>Firebase</a>, Google’s flagship “backend-as-a-service” app platform.</p><p>Firebase’s big selling point for early-stage app development is that it abstracts away the need to write a full backend and maintain one’s own database. Firebase can handle <a href=https://firebase.google.com/docs/auth target=_blank>authentication</a> (including MFA and SSO solutions) and its document-structured <a href=https://firebase.google.com/docs/firestore target=_blank>Cloud Firestore (CFS)</a> and <a href=https://firebase.google.com/docs/database target=_blank>Realtime Database (RTDB)</a> datastore offerings allow significant flexibility in terms of the data they can store. This is extremely appealing to developers in an early or prototyping stage as data models can change frequently.</p><h1 id=firebase-and-data-security>Firebase and data security</h1><p>As Firebase serves as the backend itself, clients such as web and mobile apps connect directly to both the authentication system and to the datastore itself using a set of API keys that are distributed with every client instance (i.e., every app download has the same set of Firebase API keys embedded in it). There is no programmatic authorization system for restricting which clients can see what data, as there would be in a traditional client-server-database model.</p><p><img class=img-zoomable src=https://uploads-ssl.webflow.com/5e39239f2e417c1a357f71f5/60927deba737083eb80929d0_traditional-firebase.svg alt="Firebase&amp;rsquo;s client model versus traditional. Credit to Iosiro Security for the image"></p><p>Instead, data access limitations are configured in the admin view using <a href=https://firebase.google.com/docs/rules target=_blank>JSON-based security rules</a>, which allows developers to specify which classes of users are allowed to read or write to and from each data path. When data models start to involve any modicum of complexity, configuring these security rules to properly restrict unauthorized access to data gets tricky. From <a href=https://firebase.google.com/docs/rules#how_do_they_work target=_blank>Firebase&rsquo;s documentation</a>:</p><blockquote><p>Rules are applied as <code>OR</code> statements, not <code>AND</code> statements. Consequently, if multiple
rules match a path, and any of the matched conditions grants access, Rules grant access to the data at that path. Therefore, if a broad rule grants access to data, you can&rsquo;t restrict with a more specific rule. You can, however, avoid this problem by making sure your Rules don&rsquo;t overlap too much. Firebase Security Rules flag overlaps in your matched paths as compiler warnings.</p></blockquote><p>Exacerbating this issue is <a href=https://firebase.google.com/docs/rules/insecure-rules#open_access target=_blank>“Test Mode”</a>, the default Firebase security configuration when initially setting up an app. Test Mode grants read and write access on all data to all users on the open internet (regardless of whether they have an app account or not) using the following rule:</p><pre><code class=language-json>match /{document=**} {
  allow read, write: if request.time &lt; timestamp.date(2022, 10, 13);
}
</code></pre><p>This is great in a pre-launch environment when nobody but the developers know of the existence of the Firebase project. However, in early-stage startups, security often takes a backseat to other development tasks, and it’s not a rare occurrence that Firebase collections are often left in Test Mode well after launch.</p><p>In fact, a 2020 <a href=https://www.comparitech.com/blog/information-security/firebase-misconfiguration-report/#What_data_is_exposed target=_blank>report</a> by Comparitech showed that nearly eight percent of Android apps on the Google Play Store using Firebase had security rules that allowed attackers to potentially read personal user information without even requiring authentication. More than 75 percent of these apps also allowed write access by arbitrary users on their database collections. There are likely even more apps that are vulnerable to data access by authenticated users of other users’ personal information (i.e., user authentication is required to access a collection, but once a user has authenticated they can access any other user’s data).</p><p>These Firebase issues represent a larger class of security vulnerabilities known as <a href=https://symantec-enterprise-blogs.security.com/blogs/expert-perspectives/symantec-discusses-securing-private-mobile-app-data-cloud target=_blank>HospitalGown</a>, where client-side applications connect to a completely exposed backend that simply allow malicious users to query for data they should not have access to.</p><h1 id=anatomy-of-a-firebase-data-breach>Anatomy of a Firebase data breach</h1><p>The overarching idea of finding an unauthorized data access vulnerability in a Firebase client app is to pretend to be a client that can request anything from the datastore regardless of what data the real client queries for.</p><h2 id=becoming-a-firebase-client>Becoming a Firebase client</h2><p>To identify oneself as a client to Firebase involves using a set of API tokens of the following format:</p><pre><code class=language-json>{
  apiKey: &quot;AIzaSyCad_1JSDfJBl399DFkseNqR63246PLEF4&quot;, // created by keyboard mashing
  authDomain: &quot;my-project.firebaseapp.com&quot;,
  projectId: &quot;my-project&quot;,
  storageBucket: &quot;my-project.appspot.com&quot;,
  databaseURL: &quot;https://my-project.firebaseio.com&quot;, // used only by RTDB
  messagingSenderId: &quot;70263983361&quot;, // randomized
  appId: &quot;1:70263983361:web:907b0c94510e7549e1ae94&quot; // randomized
}
</code></pre><p>It&rsquo;s not particularly difficult to find these tokens:</p><ul><li>On Web apps, they are typically located somewhere in the minified Javascript source code for the page - typically, search for the phrase <code>appspot</code> and you should be able to find them (already in JSON format).</li><li>For Android apps, you can download the app APK to your computer using a tool such as <a href=https://apps.evozi.com/apk-downloader/ target=_blank>this one</a>. After decompiling the app using <code>apktool</code>, you can find the keys in the file <code>res/values/strings.xml</code> by searching for the keyword <code>firebase</code>. You&rsquo;ll want the values associated with the following XML keys:<ul><li><code>gcm_defaultSenderId</code></li><li><code>google_api_key</code></li><li><code>firebase_url</code> (for RTDB client apps)</li><li><code>google_storage_bucket</code></li><li><code>google_app_id</code></li><li><code>project_id</code></li></ul></li><li>iOS apps are a little trickier, and finding the tokens usually requires access to a jailbroken iPhone or iPad. To find the tokens, <code>ssh</code> into the iPhone and navigate to the directory <code>/var/containers/Bundle/Application</code>. Find the UUID of the app by running <code>find | grep com.appdev.app_name</code>, then run <code>cd app_uuid/app_name.app</code>. The tokens are located in the file <code>GoogleService-Info.plist</code>. This file might be binary encoded and may require using a tool like <code>plistutil</code> to reveal in plaintext; this can be done by using <code>scp</code> to transfer the file back to your computer. You&rsquo;ll want the values associated with the following keys:<ul><li><code>API_KEY</code></li><li><code>DATABASE_URL</code> (for RTDB client apps)</li><li><code>GCM_SENDER_ID</code></li><li><code>GOOGLE_APP_ID</code></li><li><code>PROJECT_ID</code></li><li><code>STORAGE_BUCKET</code></li></ul></li></ul><h2 id=probing-the-datastore>Probing the datastore</h2><p>Once you have the API tokens, the easiest way to start spelunking around the database is to use <a href=https://github.com/iosiro/baserunner target=_blank>Baserunner</a>, which allows you to set a Firebase config in JSON format for a particular app and then authenticate into that app if necessary. Authentication is supported via email/password, phone number/OTP, and via Google account (this was <a href=https://github.com/iosiro/baserunner/pull/12 target=_blank>my contribution</a>, and the motivation and implementation of this feature will be the subject of a future blog post).</p><p><img class=img-zoomable src=https://uploads-ssl.webflow.com/5e39239f2e417c1a357f71f5/60927ddd3ccc704c3bb86a9d_baserunner-in-action.png alt="Baserunner UI, credit to Iosiro Security for the image"></p><p>Once authenticated into the datastore for the app you&rsquo;re testing, you can use a query template to start trying to request data from CFS or RTDB (depending on what the app uses). Doing so requires knowing or guessing collection and potentially document names that correspond to valid data for the app. There are ways to make this easier, such as searching through Javascript source code in web or React Native apps, or by using a gRPC-capable proxy such as <a href=https://github.com/mitmproxy/mitmproxy target=_blank>mitmproxy</a> to intercept and inspect requests between mobile clients and Firebase.</p><p>Note that many Firebase client apps and websites often use SSL certificate pinning when accessing the database, making traffic proxying difficult. One workaround might be to use one of mitmproxy&rsquo;s suggested <a href=https://docs.mitmproxy.org/stable/concepts-certificates/#certificate-pinning target=_blank>certificate pinning bypass techniques</a>, although I haven&rsquo;t tried any of them.</p><p>However, if you&rsquo;re blindly guessing at names, keep in mind how <a href=https://firebase.google.com/docs/firestore/data-model target=_blank>Cloud Firestore</a> and <a href=https://firebase.google.com/docs/database/web/structure-data target=_blank>Realtime Database</a> structure their data models, especially this restriction for Cloud Firestore:</p><blockquote><p>Notice the alternating pattern of collections and documents. Your collections and documents must always follow this pattern. You cannot reference a collection in a collection or a document in a document.</p></blockquote><p>Note that if you try to access an invalid data path, Firebase&rsquo;s client library used in Baserunner will always return a permission denied error. This is due to a security feature in Firebase that prevents distinguishing on the frontend if a data path is invalid or if security rules prevent the authenticated user from accessing that data path. To make sure your tooling is working, try accessing a data path that you know you should have access to (which you can probably find by inspecting web requests or Javascript minified source).</p><h1 id=case-study-the-fizz-vulnerabilities>Case study: the Fizz vulnerabilities</h1><p><a href=https://fizzsocial.app target=_blank>Fizz</a>, formerly Buzz, is an iOS-only social messaging platform for sharing posts and associated comments that’s popular at Stanford and other college campuses. The app is structured such that each user has an account that requires a community-affiliated email to verify membership, but can post anonymously. Users can accrue points based on the popularity of their posts.</p><p><img class=img-zoomable src=https://is4-ssl.mzstatic.com/image/thumb/Purple122/v4/55/c1/e7/55c1e701-b2df-a501-4f5a-48a506f7f0e5/c780362b-3e00-40ae-92dd-cdb75e12b6fb_Latest_Updates_6.5.png/230x0w.png alt="Screenshot of Fizz from their App Store listing"></p><p>Owing to its purportedly anonymous nature, Fizz posts can often consist of highly sensitive information. For example, users often use the platform to talk about their LGBTQ+ identity, even while in family situations that are not supportive of said identity.</p><h2 id=conducting-security-testing-on-fizz>Conducting security testing on Fizz</h2><p>In November 2021, <a href=https://miles.land target=_blank>Miles McCain</a>, <a href=https://github.com/cdenicola target=_blank>Cooper de Nicola</a>, and I did an <a href=https://cheatsheetseries.owasp.org/cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html target=_blank>inspection</a> of Fizz&rsquo;s security posture and found significant data leakage due to the app&rsquo;s developers having misconfigured their Firebase security rules.</p><p>To do this testing, we first used the aforementioned iOS <a href=#becoming-a-firebase-client>token extraction technique</a> to pull the Firebase API keys off a jailbroken iPhone 6S.</p><p>We did the inspection before we knew of Baserunner&rsquo;s existence, so we wrote a Node.js script based on the Firebase SDK that could identify itself to Firebase as Fizz using the tokens we found in the app files.</p><pre><code class=language-js>import { initializeApp } from 'firebase/app';
import { getFirestore, collection, getDocs } from 'firebase/firestore/lite';
import { getAuth, createUserWithEmailAndPassword, deleteUser } from &quot;firebase/auth&quot;;

const firebaseConfig = {
    // Fizz tokens go here
};

const app = initializeApp(firebaseConfig);
const db = getFirestore(app);
const auth = getAuth();

createUserWithEmailAndPassword(
    auth,
    &quot;not-real-user-&quot; + Math.random() + &quot;@test.com&quot;,
    &quot;foo&quot;
).then((userCredential)) =&gt; {
    getDocs(collection(db, &quot;users&quot;)).then(x =&gt; {
        x.forEach((doc) =&gt; {
            console.log(JSON.stringify(doc.data()));
        });
    });

    deleteUser(auth.currentUser);
};
</code></pre><p>Fizz&rsquo;s minimal security rules required a user session to be active when data is requested from the database, and their user authentication model at the time consisted of sending a sign-in link to the user&rsquo;s email. Simulating this would have been extremely difficult with a script; Baserunner is much easier to use here as it saves such state for you in the session.</p><p>However, the email associated with a user session did not need to be affiliated with a member community in order to access data. Thus, we were able to make temporary users with email <code>not-real-user-RANDOM@test.com</code> for each run of the script.</p><h2 id=pulling-out-the-data>Pulling out the data</h2><p>We first requested the <code>users</code> collection; this contained the expected information such as emails, phone numbers, app points accrued, and moderator status. We noticed there was also a <code>userID</code> field and theorized that this field would be what connected the <code>users</code> and <code>posts</code> collections.</p><p><img class=img-zoomable src=/blog/images/fizz_users.png alt="Fizz users collection columns"></p><p>We were then able to request the <code>posts</code> collection; finding this was a bit trickier because the table was namespaced under a specific member of the <code>communities</code> collection. That is, each community has its own posts table.</p><p><img class=img-zoomable src=/blog/images/fizz_posts.png alt="Fizz posts collection columns"></p><p>This contained a treasure trove of information for each post including post content, pseudonyms, the user ID of the user that created it, the user IDs of the users that upvoted and downvoted the posts, and more. This effectively broke app anonymity because with a join of the <code>users</code> and <code>posts</code> collection on the user ID fields, each post’s author could be identified down to their email address and/or phone number.</p><p>We also found that the <code>users</code> collection could be modified. We were able to change the points value of my user account to 99 trillion, and the modification was then reflected when opening the app.</p><p><img class=img-zoomable src=/blog/images/fizz_karma_mod.png alt="Points value modified to 99 trillion"></p><p>More concerning, however, was that we could easily promote the account to be a moderator by simply changing the <code>isModerator</code> field on my account from <code>null</code> to <code>true</code>. This gave me access to a moderation UI and the ability to delete arbitrary posts from the app itself, including those made by accounts that were not my own (note that the only posts that were deleted were created by Miles for testing purposes). We reverted all modifications immediately after taking screenshots from the app for documentation purposes, and we only modified accounts that we had express consent from the owners to access (indeed, the only accounts we modified were our own)..</p><p><img class=img-zoomable src=/blog/images/fizz_mod_ui.png alt="Fizz moderator UI">
<img class=img-zoomable src=/blog/images/fizz_mod_remove_post.png alt="Remove other user&amp;rsquo;s post option">
<img class=img-zoomable src=/blog/images/fizz_mod_remove_post_gone.png alt="Successfully removed other user&amp;rsquo;s post"></p><h2 id=disclosure>Disclosure</h2><p>Concerned about user privacy and security — and consistent with <a href=https://cheatsheetseries.owasp.org/cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#responsible-or-coordinated-disclosure target=_blank>industry best practices</a> — we wrote a detailed email to the Fizz team on November 8, 2021 documenting the issues and explaining how to fix them. Given how fundamental this vulnerability was, we believe it is possible that it was noticed (and perhaps even abused) by others before we discovered it. We felt strongly that Fizz had an obligation to notify their users of the issue. In order to give Fizz enough time to resolve the vulnerability itself, we agreed not to publicly disclose the issue ourselves until December 8.</p><h3 id=fizzs-response-initial-courtesy-then-a-lawsuit-threat>Fizz&rsquo;s response: initial courtesy, then a lawsuit threat</h3><p>Fizz initially thanked us for our report, and they worked to fix the issue. Over the course of several emails, we thanked the Fizz team for handling our report well and advised them on the effectiveness of their fix. Things were looking good, and on November 22, Fizz let us know that they considered the original vulnerability fixed.</p><p>In that email, however, they also attached an <a href=https://stanforddaily.com/wp-content/uploads/2022/11/Buzz_Letter_Vulnerability_Disclosure_Redacted.pdf target=_blank>aggressive legal threat</a> from their lawyer at <a href=https://www.hopkinscarley.com/ target=_blank>Hopkins & Carley</a>, a Silicon Valley law firm. The letter demanded that, unless we agreed to various terms — including staying silent about vulnerabilities we discovered in Fizz and their misleading claims on encryption and user anonymity — they would “pursue charges.” If we didn&rsquo;t agree to gag ourselves within five calendar days (most of those days occurring over the Thanksgiving holiday), they threatened to &ldquo;pursue charges&rdquo; in the form of civil, criminal, and disciplinary action. They alleged that by performing a security audit on their systems, we had violated the Computer Fraud and Abuse Act (CFAA) and the Digital Millennium Copyright Act (DMCA).</p><p>The next day, our friend <a href=https://cablej.io/ target=_blank>Jack Cable</a>, a fellow Stanford student and security researcher, reached out to Kurt Opsahl and Andrew Crocker of the Electronic Frontier Foundation, who agreed to represent us pro bono in the dispute. On our behalf, they sent a <a href=https://stanforddaily.com/wp-content/uploads/2022/11/Response-to-Buzz-Vulnerability-Disclosure-Letter-vp_Redacted.pdf target=_blank>letter</a> that disputed Fizz&rsquo;s claims of DMCA and CFAA violations. Additionally, they noted that Fizz&rsquo;s lawyers conditioning of criminal charges on our signing of an NDA violated a California bar rule.</p><p>After the EFF’s letter was received, Fizz’s founders posted a public <a href=https://archive.ph/Oc9lg target=_blank>security notice</a> on their website on December 7, informing users that they had adequately remediated the issues following our disclosure. But the presentation of that statement was somewhat questionable, as it was presented to Fizz users only when opening the app for the first time post-disclosure and framed as mere &ldquo;security improvements&rdquo; rather than the severe data breach it really was. Additionally, their statement did not adequately disclose the fact that we were able to deanonymize every single post on the app.</p><p>Outside of some limited word-of-mouth communication, most Fizz users likely were not informed of how severe the vulnerabilities we found were until the Stanford Daily released its <a href=https://stanforddaily.com/2022/11/01/opinion-fizz-previously-compromised-its-users-privacy-it-may-do-so-again/ target=_blank>article</a> about the situation nearly a year later.</p><h1 id=remediation-and-conclusions>Remediation and conclusions</h1><p>Firebase vulnerabilities are unfortunately all too common and can be quite devastating for certain business models, as the Fizz case study shows. Fizz was not the only app that we were able to find significant Firebase vulnerabilities in; we and other Stanford security researchers have identified this type of issue in numerous other startup apps.</p><p>For this class of Firebase-related vulnerabilities specifically, remediation must be done through careful application of security rules to the datastore in order to restrict data to only those that are authorized to see it. Due to the semantics of how these rules are interpreted, doing so is tricky. Many other apps I’ve inspected have made good attempts to write these rules but were still susceptible to unauthorized data accesses through edge cases. Developers must be extremely careful to test every potential user role and every data access path to confirm the efficacy of their rules.</p><p>Another thing I&rsquo;ve seen apps do is use simplistic rules that are nearly as insecure as Test Mode, such as permitting all requests by authenticated users. Such rules sometimes end up being a <a href=https://cardinalkit.org/cardinalkit-docs/1-cardinalkit-app/2-setup.html#_5-setting-up-sign-in-with-google-optional target=_blank><em>suggested</em> implementation</a> by introductory development tutorials.</p><p>Not all the blame can be placed entirely on developers. In my opinion, Google does not go far enough to help developers protect themselves against these vulnerabilities. When choosing Test Mode in the console for a Firebase database, there is a warning displayed about such issues, and by default Test Mode expires 30 days after creation. Google bombards developers with emails about Test Mode expiry containing a short warning about unauthorized data accesses.</p><p>However, I think developers tend to continuously reset the Test Mode timer well into the production cycle rather than working on better security rules, particularly if they are in a rapid-growth and feature-addition phase. In addition, Google has no way of warning developers of nearly-as-insecure rules such as those mentioned above.</p><p><img class=img-zoomable src=/blog/images/firebase_test_mode_warning.png alt="Firebase test mode email warning"></p><p>Google should add stronger warnings to Firebase documentation in addition to emails and the console, such that developers truly understand the importance of setting proper security rules in a timely manner. This documentation must be easily accessible and written in a way that new developers can understand and implement these rules, given Firebase&rsquo;s target market. Additionally, Google should also develop a way to click on any collection or document and see exactly which users or roles have access to that document. This would allow developers to self-test their rules without too much extra effort.</p><p>Broadly, startups having poor security is not just a Firebase problem, but rather a systemic one. Security is <a href=https://hbr.org/2019/08/every-computer-science-degree-should-require-a-course-in-cybersecurity target=_blank>almost never a required course</a> for any university computer science curriculum, including at Stanford, leading to student startups not knowing where to start in terms of securely designing their product. Even when they do, the &ldquo;move fast, break things&rdquo; mindset of the wider startup culture and ecosystem incentivizes startups to concentrate on rapid growth and scale rather than robust and secure development.</p><p>This means that the culture around early-stage startups and computer science curricula must change to incorporate the importance of security and safety as a core foundation. Such a change must be embraced by educators, entrepreneurs, and venture capitalists to further a security culture.</p><p>As the Fizz case study demonstrates, Stanford is one place this culture shift is desperately needed. As such, I&rsquo;m trying to focus many of my efforts this year as Vice President of Stanford&rsquo;s Applied Cybersecurity club on two goals: making security cool, and making people take security seriously. I plan to write more on this topic in the near future.</p></div></article><div class="license markdown-body"><blockquote><p>Unless otherwise noted, the content of this site is licensed under <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a>.</p></blockquote></div></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/blog/>Home</a></li><li><a href=/blog/index.xml>RSS</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://saligrama.io target=_blank><span>About me</span></a></li><li><a href=https://github.com/saligrama target=_blank><span>GitHub</span></a></li><li><a href=https://twitter.com/saligrama_a target=_blank><span>Twitter</span></a></li><li><a href=https://linkedin.com/in/saligrama target=_blank><span>Linkedin</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#firebase-and-data-security>Firebase and data security</a></li><li><a href=#anatomy-of-a-firebase-data-breach>Anatomy of a Firebase data breach</a><ul><li><a href=#becoming-a-firebase-client>Becoming a Firebase client</a></li><li><a href=#probing-the-datastore>Probing the datastore</a></li></ul></li><li><a href=#case-study-the-fizz-vulnerabilities>Case study: the Fizz vulnerabilities</a><ul><li><a href=#conducting-security-testing-on-fizz>Conducting security testing on Fizz</a></li><li><a href=#pulling-out-the-data>Pulling out the data</a></li><li><a href=#disclosure>Disclosure</a><ul><li><a href=#fizzs-response-initial-courtesy-then-a-lawsuit-threat>Fizz&rsquo;s response: initial courtesy, then a lawsuit threat</a></li></ul></li></ul></li><li><a href=#remediation-and-conclusions>Remediation and conclusions</a></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/blog/>Home</a></li><li><a href=/blog/index.xml>RSS</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://saligrama.io target=_blank><span>About me</span></a></li><li><a href=https://github.com/saligrama target=_blank><span>GitHub</span></a></li><li><a href=https://twitter.com/saligrama_a target=_blank><span>Twitter</span></a></li><li><a href=https://linkedin.com/in/saligrama target=_blank><span>Linkedin</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#firebase-and-data-security>Firebase and data security</a></li><li><a href=#anatomy-of-a-firebase-data-breach>Anatomy of a Firebase data breach</a><ul><li><a href=#becoming-a-firebase-client>Becoming a Firebase client</a></li><li><a href=#probing-the-datastore>Probing the datastore</a></li></ul></li><li><a href=#case-study-the-fizz-vulnerabilities>Case study: the Fizz vulnerabilities</a><ul><li><a href=#conducting-security-testing-on-fizz>Conducting security testing on Fizz</a></li><li><a href=#pulling-out-the-data>Pulling out the data</a></li><li><a href=#disclosure>Disclosure</a><ul><li><a href=#fizzs-response-initial-courtesy-then-a-lawsuit-threat>Fizz&rsquo;s response: initial courtesy, then a lawsuit threat</a></li></ul></li></ul></li><li><a href=#remediation-and-conclusions>Remediation and conclusions</a></li></ul></nav></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2022-2023
<a href=https://saligrama.io/blog>Aditya Saligrama</a>
| <a href=https://github.com/saligrama/blog>Source code</a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js></script>
<script defer src=/blog/assets/js/fuji.min.js></script></body></html>